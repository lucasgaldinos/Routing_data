---
config:
  theme: base
  themeVariables:
    primaryColor: '#e8f4f8'
    primaryTextColor: '#0d47a1'
    primaryBorderColor: '#1565c0'
    lineColor: '#1976d2'
    fontFamily: 'Segoe UI, Arial, sans-serif'
    fontSize: 10px
    background: '#fafafa'
  flowchart:
    htmlLabels: true
    curve: basis
    useMaxWidth: true
    diagramPadding: 20
title: Complete Processing Pipeline Flow - TSPLIB95 ETL System
---
flowchart TD
    subgraph input_layer["ğŸ“ Input Layer"]
        file_discovery["ğŸ” File Discovery<br/>Scanner.scan_files()<br/>â”Œâ”€ Recursive directory walk<br/>â”œâ”€ Pattern matching: *.tsp, *.vrp, etc.<br/>â”œâ”€ File size validation<br/>â”œâ”€ Permission checks<br/>â””â”€ Batch grouping by size"]
        
        change_detection["â±ï¸ Change Detection<br/>UpdateManager.detect_changes()<br/>â”Œâ”€ File modification time check<br/>â”œâ”€ Content hash comparison<br/>â”œâ”€ Database record lookup<br/>â””â”€ Skip unchanged files (unless --force)"]
        
        file_validation["âœ… File Validation<br/>validate_file_size()<br/>â”Œâ”€ Size limit check (default 100MB)<br/>â”œâ”€ Read permission verification<br/>â”œâ”€ Character encoding detection<br/>â””â”€ Basic format sanity check"]
    end
    
    subgraph processing_layer["âš™ï¸ Processing Layer"]
        subgraph parallel_coord["ğŸ‘¥ Parallel Coordination"]
            batch_manager["ğŸ“¦ Batch Manager<br/>ParallelProcessor.process_batches()<br/>â”Œâ”€ Group files by estimated processing time<br/>â”œâ”€ Assign batches to available workers<br/>â”œâ”€ Monitor memory usage per worker<br/>â””â”€ Handle worker failures and recovery"]
            
            worker_pool["ğŸ‘· Worker Pool<br/>Process Pool (configurable size)<br/>â”Œâ”€ Independent parser instances<br/>â”œâ”€ Local database connections<br/>â”œâ”€ Memory limit enforcement<br/>â””â”€ Progress reporting to coordinator"]
        end
        
        subgraph worker_process["ğŸ”§ Worker Process (Per File)"]
            parse_phase["ğŸ“Š Phase 1: Parse<br/>TSPLIBParser.parse_file()<br/>â”Œâ”€ Load file with tsplib95 library<br/>â”œâ”€ Extract StandardProblem object<br/>â”œâ”€ Validate TSPLIB format compliance<br/>â”œâ”€ Handle SPECIAL distance types<br/>â””â”€ Preserve 1-based indexing"]
            
            validate_phase["ğŸ” Phase 1.5: Validate<br/>validate_problem_data()<br/>â”Œâ”€ Check dimension consistency<br/>â”œâ”€ Validate coordinate ranges<br/>â”œâ”€ Verify tour feasibility<br/>â”œâ”€ Check capacity constraints (VRP)<br/>â””â”€ Handle missing or invalid data"]
            
            transform_phase["ğŸ”„ Phase 2: Transform<br/>DataTransformer.transform_problem()<br/>â”Œâ”€ Convert 1-based â†’ 0-based indexing<br/>â”œâ”€ Normalize node data structure<br/>â”œâ”€ Process edges (EXPLICIT only)<br/>â”œâ”€ Clean and validate coordinates<br/>â””â”€ Structure for database insertion"]
            
            load_phase["ğŸ’¾ Phase 3: Load<br/>Parallel Database + JSON Output<br/>â”Œâ”€ DatabaseManager.insert_problem()<br/>â”œâ”€ JSONWriter.write_problem()<br/>â”œâ”€ Update file tracking record<br/>â””â”€ Commit transaction or rollback"]
        end
    end
    
    subgraph error_handling["ğŸš¨ Error Handling & Recovery"]
        error_classification["ğŸ·ï¸ Error Classification<br/>Exception Hierarchy<br/>â”Œâ”€ ParsingError: TSPLIB format issues<br/>â”œâ”€ ValidationError: Data integrity problems<br/>â”œâ”€ DatabaseError: Storage/transaction issues<br/>â”œâ”€ FileProcessingError: I/O problems<br/>â””â”€ ConfigurationError: Setup issues"]
        
        recovery_strategies["ğŸ”„ Recovery Strategies<br/>Based on Error Type<br/>â”Œâ”€ Retry with relaxed validation<br/>â”œâ”€ Skip corrupted file sections<br/>â”œâ”€ Fallback to partial data extraction<br/>â”œâ”€ Continue processing other files<br/>â””â”€ Detailed logging for manual review"]
        
        graceful_degradation["âš ï¸ Graceful Degradation<br/>When Errors Occur<br/>â”Œâ”€ Preserve partial results<br/>â”œâ”€ Update processing status<br/>â”œâ”€ Generate detailed error report<br />â”œâ”€ Continue with remaining files<br/>â””â”€ Provide recovery recommendations"]
    end
    
    subgraph output_layer["ğŸ“¤ Output Layer"]
        subgraph database_output["ğŸ—„ï¸ Database Output"]
            db_transaction["ğŸ’¼ Database Transaction<br/>ACID Compliance<br/>â”Œâ”€ BEGIN TRANSACTION<br/>â”œâ”€ Insert into problems table<br/>â”œâ”€ Bulk insert nodes<br/>â”œâ”€ Bulk insert edges (if EXPLICIT)<br/>â”œâ”€ Insert tours (if available)<br/>â”œâ”€ Update file_tracking<br/>â””â”€ COMMIT or ROLLBACK"]
            
            db_optimization["âš¡ Performance Optimization<br/>Bulk Operations<br/>â”Œâ”€ Prepared statements<br/>â”œâ”€ Batch inserts (100-1000 rows)<br/>â”œâ”€ Index maintenance<br/>â”œâ”€ Memory-mapped I/O<br/>â””â”€ Connection pooling"]
        end
        
        subgraph json_output["ğŸ“„ JSON Output"]
            json_structure["ğŸ“‹ JSON Structuring<br/>Flattened Format<br/>â”Œâ”€ Problem metadata object<br/>â”œâ”€ Nodes array (0-based indexing)<br/>â”œâ”€ Solution data (if available)<br/>â”œâ”€ Metadata (file info, timing)<br/>â””â”€ Validation checksums"]
            
            json_writing["âœï¸ File Writing<br/>Atomic Operations<br/>â”Œâ”€ Write to temporary file<br/>â”œâ”€ Validate JSON structure<br/>â”œâ”€ Atomic rename operation<br/>â”œâ”€ Set appropriate permissions<br/>â””â”€ Update directory index"]
        end
    end
    
    subgraph monitoring_layer["ğŸ“Š Monitoring & Reporting"]
        progress_tracking["ğŸ“ˆ Progress Tracking<br/>Real-time Monitoring<br/>â”Œâ”€ Files processed / total<br/>â”œâ”€ Processing rate (files/sec)<br/>â”œâ”€ Estimated time remaining<br/>â”œâ”€ Memory usage per worker<br/>â””â”€ Error rate monitoring"]
        
        performance_metrics["â±ï¸ Performance Metrics<br/>Detailed Statistics<br/>â”Œâ”€ Parse time per file<br/>â”œâ”€ Transform time per file<br/>â”œâ”€ Database insertion time<br/>â”œâ”€ JSON writing time<br/>â””â”€ End-to-end processing time"]
        
        result_summary["ğŸ“‹ Result Summary<br/>Processing Report<br/>â”Œâ”€ Total files processed<br/>â”œâ”€ Success/failure counts<br/>â”œâ”€ Performance statistics<br/>â”œâ”€ Error summary by type<br/>â””â”€ Recommendations for failures"]
    end
    
    subgraph memory_management["ğŸ§  Memory Management"]
        memory_monitoring["ğŸ“Š Memory Monitoring<br/>Per-Worker Tracking<br/>â”Œâ”€ RSS (Resident Set Size)<br/>â”œâ”€ Peak memory usage<br/>â”œâ”€ Memory growth rate<br/>â””â”€ GC trigger thresholds"]
        
        memory_limits["ğŸš« Memory Limits<br/>Enforcement Strategy<br/>â”Œâ”€ Configurable per-worker limit<br/>â”œâ”€ Batch size adjustment<br/>â”œâ”€ Emergency garbage collection<br/>â”œâ”€ Process restart if needed<br/>â””â”€ User notification on limits"]
        
        memory_optimization["âš¡ Memory Optimization<br/>Efficiency Techniques<br/>â”Œâ”€ Streaming large file processing<br/>â”œâ”€ Lazy edge computation<br/>â”œâ”€ Object pooling for frequent allocations<br/>â”œâ”€ Reference cycle detection<br/>â””â”€ Explicit cleanup after batch"]
    end
    
    %% Flow connections
    file_discovery --> change_detection
    change_detection --> file_validation
    file_validation --> batch_manager
    batch_manager --> worker_pool
    worker_pool --> parse_phase
    parse_phase --> validate_phase
    validate_phase --> transform_phase
    transform_phase --> load_phase
    
    %% Error handling connections
    parse_phase --> error_classification
    validate_phase --> error_classification
    transform_phase --> error_classification
    load_phase --> error_classification
    error_classification --> recovery_strategies
    recovery_strategies --> graceful_degradation
    
    %% Output connections
    load_phase --> db_transaction
    load_phase --> json_structure
    db_transaction --> db_optimization
    json_structure --> json_writing
    
    %% Monitoring connections
    worker_pool --> progress_tracking
    parse_phase --> performance_metrics
    transform_phase --> performance_metrics
    load_phase --> performance_metrics
    batch_manager --> result_summary
    
    %% Memory management connections
    worker_pool --> memory_monitoring
    memory_monitoring --> memory_limits
    memory_limits --> memory_optimization
    memory_optimization --> batch_manager
    
    classDef inputLayer fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef processingLayer fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef errorHandling fill:#ffebee,stroke:#d32f2f,stroke-width:2px
    classDef outputLayer fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    classDef monitoringLayer fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef memoryManagement fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class file_discovery,change_detection,file_validation inputLayer
    class batch_manager,worker_pool,parse_phase,validate_phase,transform_phase,load_phase processingLayer
    class error_classification,recovery_strategies,graceful_degradation errorHandling
    class db_transaction,db_optimization,json_structure,json_writing outputLayer
    class progress_tracking,performance_metrics,result_summary monitoringLayer
    class memory_monitoring,memory_limits,memory_optimization memoryManagement