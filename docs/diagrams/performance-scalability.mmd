---
config:
  theme: base
  themeVariables:
    primaryColor: '#e0f2f1'
    primaryTextColor: '#00695c'
    primaryBorderColor: '#00897b'
    lineColor: '#26a69a'
    fontFamily: 'JetBrains Mono, Monaco, Consolas, monospace'
    fontSize: 10px
    background: '#fafafa'
  flowchart:
    htmlLabels: true
    curve: basis
    useMaxWidth: true
    diagramPadding: 20
title: Performance Characteristics and Scalability Analysis - TSPLIB95 ETL System
---
flowchart TD
    subgraph performance_metrics["ğŸ“Š Performance Metrics & Benchmarks"]
        subgraph parsing_performance["ğŸ“– Parsing Performance"]
            parse_benchmarks["â±ï¸ Parsing Benchmarks<br/>File Size vs Processing Time<br/>â”Œâ”€ Small files (<1MB): ~50ms<br/>â”œâ”€ Medium files (1-10MB): ~200-500ms<br/>â”œâ”€ Large files (10-100MB): ~2-15s<br/>â”œâ”€ Very large files (>100MB): ~30s+<br/>â””â”€ Bottlenecks:<br/>   â”œâ”€ Regex parsing: O(n) file scanning<br/>   â”œâ”€ String operations: Memory allocation<br/>   â””â”€ Validation: Coordinate range checks<br/><br/>ğŸ“ˆ Scaling Characteristics:<br/>â€¢ Linear with file size<br/>â€¢ Memory usage: ~3x file size peak<br/>â€¢ CPU bound for parsing phase<br/>â€¢ I/O bound for very large files"]
            
            parse_complexity["ğŸ§® Computational Complexity<br/>Algorithm Analysis<br/>â”Œâ”€ File scanning: O(n) n=file_size<br/>â”œâ”€ Node parsing: O(d) d=dimension<br/>â”œâ”€ Edge parsing: O(e) e=explicit_edges<br/>â”œâ”€ Coordinate validation: O(d)<br/>â””â”€ Index conversion: O(d + e)<br/><br/>Critical Path:<br/>â€¢ EXPLICIT edge types: O(dÂ²) avoided<br/>â€¢ Coordinate types: O(d) preferred<br/>â€¢ Memory allocation: Major bottleneck<br/>â€¢ Garbage collection: 10-20% overhead"]
        end
        
        subgraph database_performance["ğŸ—„ï¸ Database Performance"]
            db_benchmarks["ğŸ’¾ Database Operation Benchmarks<br/>DuckDB Performance Characteristics<br/>â”Œâ”€ Single problem insert: ~5-50ms<br/>â”œâ”€ Batch insert (100 problems): ~200-800ms<br/>â”œâ”€ Node bulk insert (10k nodes): ~100ms<br/>â”œâ”€ Query simple problem: ~1ms<br/>â”œâ”€ Complex analytics query: ~50-500ms<br/>â””â”€ Database size growth:<br/>   â”œâ”€ 1k problems: ~10MB<br/>   â”œâ”€ 10k problems: ~100MB<br/>   â””â”€ 100k problems: ~1GB<br/><br/>ğŸš€ Optimization Features:<br/>â€¢ Columnar compression: ~5x reduction<br/>â€¢ Memory-mapped I/O: Fast random access<br/>â€¢ Vectorized operations: SIMD acceleration<br/>â€¢ Parallel query execution: Multi-core usage"]
            
            db_scaling["ğŸ“ˆ Database Scaling Behavior<br/>Collection Size vs Performance<br/>â”Œâ”€ Query time scaling:<br/>â”‚  â”œâ”€ Simple filters: O(log n) with indexes<br/>â”‚  â”œâ”€ Aggregations: O(n) but vectorized<br/>â”‚  â”œâ”€ Joins: O(nÃ—m) optimized by planner<br/>â”‚  â””â”€ Full table scans: O(n) columnar<br/>â”œâ”€ Insert scaling:<br/>â”‚  â”œâ”€ Single inserts: O(log n)<br/>â”‚  â”œâ”€ Bulk inserts: ~O(1) amortized<br/>â”‚  â””â”€ Index maintenance: O(log n)<br/>â””â”€ Memory usage:<br/>   â”œâ”€ Working set: ~10% of database size<br/>   â”œâ”€ Query cache: Adaptive size<br/>   â””â”€ Connection overhead: ~1MB per worker"]
        end
        
        subgraph parallel_performance["ğŸ‘¥ Parallel Processing Performance"]
            worker_scaling["ğŸ”€ Worker Scaling Analysis<br/>Performance vs Worker Count<br/>â”Œâ”€ Optimal workers: ~CPU_cores<br/>â”œâ”€ Linear scaling: Up to 8 workers<br/>â”œâ”€ Diminishing returns: >8 workers<br/>â”œâ”€ Overhead factors:<br/>â”‚  â”œâ”€ Process creation: ~50ms<br/>â”‚  â”œâ”€ IPC communication: ~1ms per message<br/>â”‚  â”œâ”€ Database connections: ~10ms setup<br/>â”‚  â””â”€ Context switching: ~0.1ms<br/>â””â”€ Bottleneck analysis:<br/>   â”œâ”€ I/O bound: Limited by disk speed<br/>   â”œâ”€ Memory bound: Limited by RAM<br/>   â”œâ”€ CPU bound: Limited by cores<br/>   â””â”€ Database bound: Connection pool size"]
            
            batch_optimization["ğŸ“¦ Batch Size Optimization<br/>Throughput vs Batch Size<br/>â”Œâ”€ Small batches (1-10 files):<br/>â”‚  â”œâ”€ Low latency: Fast feedback<br/>â”‚  â”œâ”€ High overhead: Process creation<br/>â”‚  â””â”€ Poor throughput: ~10 files/sec<br/>â”œâ”€ Medium batches (50-200 files):<br/>â”‚  â”œâ”€ Balanced trade-off<br/>â”‚  â”œâ”€ Good throughput: ~100 files/sec<br/>â”‚  â””â”€ Reasonable memory usage<br/>â”œâ”€ Large batches (500+ files):<br/>â”‚  â”œâ”€ High throughput: ~200 files/sec<br/>â”‚  â”œâ”€ High memory usage: Risk of OOM<br/>â”‚  â””â”€ Poor error isolation<br/>â””â”€ Dynamic adjustment:<br/>   â”œâ”€ Monitor memory usage<br/>   â”œâ”€ Adjust based on file sizes<br/>   â””â”€ Error rate feedback"]
        end
    end
    
    subgraph memory_analysis["ğŸ§  Memory Usage Analysis"]
        subgraph memory_patterns["ğŸ“Š Memory Usage Patterns"]
            parsing_memory["ğŸ” Parsing Memory Profile<br/>Memory Allocation Patterns<br/>â”Œâ”€ File loading: ~2x file size<br/>â”œâ”€ TSPLIB object creation: ~3x file size<br/>â”œâ”€ Validation structures: ~1x file size<br/>â”œâ”€ Transformation buffers: ~2x file size<br/>â””â”€ Peak usage: ~8x file size<br/><br/>Memory Lifecycle:<br/>â€¢ Initial allocation: File read buffer<br/>â€¢ Parse phase: Peak memory usage<br/>â€¢ Transform phase: Intermediate structures<br/>â€¢ Output phase: Database/JSON buffers<br/>â€¢ Cleanup: Explicit garbage collection<br/><br/>Optimization Opportunities:<br/>â€¢ Streaming large files<br/>â€¢ Reference sharing for immutable data<br/>â€¢ Object pooling for frequent allocations"]
            
            worker_memory["ğŸ‘· Per-Worker Memory Usage<br/>Multi-Process Memory Model<br/>â”Œâ”€ Base worker overhead: ~50MB<br/>â”œâ”€ Parser instances: ~20MB<br/>â”œâ”€ Database connection: ~10MB<br/>â”œâ”€ Processing buffers: Variable<br/>â”œâ”€ Peak per small file: ~100MB<br/>â”œâ”€ Peak per large file: ~1GB+<br/>â””â”€ Total system memory:<br/>   â””â”€ N_workers Ã— peak_per_worker<br/><br/>Memory Isolation Benefits:<br/>â€¢ Worker crash isolation<br/>â€¢ Independent GC cycles<br/>â€¢ Parallel memory allocation<br/>â€¢ No shared state contention<br/><br/>Memory Monitoring:<br/>â€¢ RSS tracking per worker<br/>â€¢ Peak usage alerts<br/>â€¢ Automatic batch size adjustment"]
        end
        
        subgraph memory_optimization["âš¡ Memory Optimization Strategies"]
            streaming_processing["ğŸŒŠ Streaming Processing<br/>Large File Handling<br/>â”Œâ”€ File size threshold: 100MB<br/>â”œâ”€ Chunk-based processing: 10MB chunks<br/>â”œâ”€ Memory-mapped file access<br/>â”œâ”€ Lazy evaluation of sections<br/>â”œâ”€ Incremental validation<br/>â””â”€ Streaming database inserts<br/><br/>Benefits:<br/>â€¢ Constant memory usage<br/>â€¢ Scalable to arbitrary file sizes<br/>â€¢ Reduced GC pressure<br/>â€¢ Better cache locality<br/><br/>Trade-offs:<br/>â€¢ Increased complexity<br/>â€¢ Potential performance overhead<br/>â€¢ Limited random access<br/>â€¢ More complex error handling"]
            
            memory_pooling["ğŸŠ Memory Pool Management<br/>Allocation Optimization<br/>â”Œâ”€ Object pools for frequent types:<br/>â”‚  â”œâ”€ Node objects: Pre-allocated<br/>â”‚  â”œâ”€ Edge objects: Reusable<br/>â”‚  â””â”€ String buffers: Size classes<br/>â”œâ”€ Memory arena allocation:<br/>â”‚  â”œâ”€ Batch-level arenas<br/>â”‚  â”œâ”€ Automatic cleanup<br/>â”‚  â””â”€ Reduced fragmentation<br/>â””â”€ Reference counting:<br/>   â”œâ”€ Shared coordinate data<br/>   â”œâ”€ Immutable problem metadata<br/>   â””â”€ Copy-on-write semantics<br/><br/>Performance Impact:<br/>â€¢ 20-30% allocation speedup<br/>â€¢ Reduced GC overhead<br/>â€¢ Better memory locality<br/>â€¢ Lower fragmentation"]
        end
    end
    
    subgraph scalability_limits["ğŸ“ Scalability Limits & Boundaries"]
        subgraph current_limits["ğŸš§ Current System Limits"]
            file_limits["ğŸ“ File-Level Limits<br/>Individual File Constraints<br/>â”Œâ”€ Maximum file size: 1GB (configurable)<br/>â”œâ”€ Maximum dimension: 1M nodes<br/>â”œâ”€ Maximum edges: 10M explicit edges<br/>â”œâ”€ Memory per file: 8GB peak<br/>â”œâ”€ Processing time: 1 hour timeout<br/>â””â”€ Practical limits observed:<br/>   â”œâ”€ TSP files: Up to 100k nodes<br/>   â”œâ”€ VRP files: Up to 10k nodes<br/>   â”œâ”€ EXPLICIT matrices: Up to 5kÃ—5k<br/>   â””â”€ Performance degradation: >50k nodes<br/><br/>Bottleneck Analysis:<br/>â€¢ Memory: Primary constraint<br/>â€¢ I/O: Secondary for large files<br/>â€¢ CPU: Rarely limiting factor<br/>â€¢ Database: Scales well with size"]
            
            system_limits["ğŸ–¥ï¸ System-Level Limits<br/>Hardware and OS Constraints<br/>â”Œâ”€ Maximum workers: CPU cores (typically 8-16)<br/>â”œâ”€ Memory limit: 50% of system RAM<br/>â”œâ”€ Database size: 1TB+ (DuckDB limit)<br/>â”œâ”€ File descriptors: OS limit (1024+)<br/>â”œâ”€ Concurrent connections: 100+ per database<br/>â””â”€ Network storage considerations:<br/>   â”œâ”€ NFS: Additional I/O latency<br/>   â”œâ”€ S3/Cloud: Network bandwidth limits<br/>   â””â”€ Local SSD: Optimal performance<br/><br/>Operating System Factors:<br/>â€¢ Virtual memory management<br/>â€¢ Process scheduling overhead<br/>â€¢ I/O subsystem efficiency<br/>â€¢ Network stack performance"]
        end
        
        subgraph scaling_strategies["ğŸš€ Scaling Strategies"]
            vertical_scaling["â¬†ï¸ Vertical Scaling (Scale Up)<br/>Single-Machine Optimization<br/>â”Œâ”€ Hardware upgrades:<br/>â”‚  â”œâ”€ More RAM: Handle larger files<br/>â”‚  â”œâ”€ More CPU cores: More workers<br/>â”‚  â”œâ”€ Faster storage: NVMe SSDs<br/>â”‚  â””â”€ Network upgrades: For remote data<br/>â”œâ”€ Software optimization:<br/>â”‚  â”œâ”€ Memory management tuning<br/>â”‚  â”œâ”€ Database configuration<br/>â”‚  â”œâ”€ Operating system tuning<br/>â”‚  â””â”€ JIT compilation benefits<br/>â””â”€ Practical limits:<br/>   â”œâ”€ Cost effectiveness: Diminishing returns<br/>   â”œâ”€ Hardware availability: High-end limits<br/>   â””â”€ Single point of failure<br/><br/>Recommended Configuration:<br/>â€¢ 64GB+ RAM for large collections<br/>â€¢ 16+ CPU cores for parallel processing<br/>â€¢ NVMe SSD for database storage<br/>â€¢ 10GbE for network storage"]
            
            horizontal_scaling["â¡ï¸ Horizontal Scaling (Scale Out)<br/>Multi-Machine Distribution<br/>â”Œâ”€ File-level distribution:<br/>â”‚  â”œâ”€ Partition files across machines<br/>â”‚  â”œâ”€ Independent processing<br/>â”‚  â”œâ”€ Result aggregation required<br/>â”‚  â””â”€ Coordination overhead<br/>â”œâ”€ Database sharding:<br/>â”‚  â”œâ”€ Partition by problem type<br/>â”‚  â”œâ”€ Partition by size ranges<br/>â”‚  â”œâ”€ Cross-shard queries complex<br/>â”‚  â””â”€ Consistency challenges<br/>â””â”€ Implementation approaches:<br/>   â”œâ”€ Container orchestration (K8s)<br/>   â”œâ”€ Message queue coordination<br/>   â”œâ”€ Distributed file systems<br/>   â””â”€ Cloud-native architectures<br/><br/>Trade-offs:<br/>â€¢ Complexity vs. scalability<br/>â€¢ Consistency vs. partition tolerance<br/>â€¢ Cost vs. performance benefits"]
        end
    end
    
    subgraph performance_monitoring["ğŸ“ˆ Performance Monitoring & Profiling"]
        subgraph real_time_monitoring["â±ï¸ Real-Time Performance Monitoring"]
            system_metrics["ğŸ–¥ï¸ System-Level Metrics<br/>Infrastructure Monitoring<br/>â”Œâ”€ CPU utilization: Per core and total<br/>â”œâ”€ Memory usage: RSS, virtual, swap<br/>â”œâ”€ I/O metrics: Read/write IOPS, throughput<br/>â”œâ”€ Network metrics: Bandwidth, latency<br/>â”œâ”€ Disk metrics: Space usage, I/O wait<br/>â””â”€ Process metrics:<br/>   â”œâ”€ Worker process health<br/>   â”œâ”€ Database connection counts<br/>   â”œâ”€ File handle usage<br/>   â””â”€ Error rates by type<br/><br/>Alerting Thresholds:<br/>â€¢ Memory usage: >80% system RAM<br/>â€¢ CPU usage: >90% sustained<br/>â€¢ I/O wait: >20% of CPU time<br/>â€¢ Error rate: >5% of processed files<br/>â€¢ Worker failures: >1 per hour"]
            
            application_metrics["ğŸ“Š Application-Level Metrics<br/>Performance Profiling<br/>â”Œâ”€ Processing rates:<br/>â”‚  â”œâ”€ Files per second<br/>â”‚  â”œâ”€ Nodes processed per second<br/>â”‚  â”œâ”€ Database inserts per second<br/>â”‚  â””â”€ JSON writes per second<br/>â”œâ”€ Latency metrics:<br/>â”‚  â”œâ”€ Parse time per file<br/>â”‚  â”œâ”€ Transform time per file<br/>â”‚  â”œâ”€ Database insert time<br/>â”‚  â””â”€ End-to-end processing time<br/>â”œâ”€ Quality metrics:<br/>â”‚  â”œâ”€ Parsing success rate<br/>â”‚  â”œâ”€ Validation failure rate<br/>â”‚  â”œâ”€ Database constraint violations<br/>â”‚  â””â”€ Data consistency checks<br/>â””â”€ Resource utilization:<br/>   â”œâ”€ Memory efficiency ratios<br/>   â”œâ”€ CPU usage distribution<br/>   â””â”€ I/O wait time analysis"]
        end
        
        subgraph performance_optimization["ğŸ”§ Performance Optimization Recommendations"]
            config_tuning["âš™ï¸ Configuration Tuning<br/>Parameter Optimization<br/>â”Œâ”€ Worker count tuning:<br/>â”‚  â”œâ”€ Start with CPU core count<br/>â”‚  â”œâ”€ Monitor memory usage<br/>â”‚  â”œâ”€ Adjust based on I/O patterns<br/>â”‚  â””â”€ Consider NUMA topology<br/>â”œâ”€ Batch size optimization:<br/>â”‚  â”œâ”€ Start with 100 files per batch<br/>â”‚  â”œâ”€ Increase for small files<br/>â”‚  â”œâ”€ Decrease for large files<br/>â”‚  â””â”€ Monitor memory pressure<br/>â”œâ”€ Memory limits:<br/>â”‚  â”œâ”€ Per-worker: 2GB default<br/>â”‚  â”œâ”€ Total system: 80% of RAM<br/>â”‚  â”œâ”€ Database cache: 25% of RAM<br/>â”‚  â””â”€ Emergency reserves: 20% of RAM<br/>â””â”€ Database configuration:<br/>   â”œâ”€ Memory allocation<br/>   â”œâ”€ Connection pool size<br/>   â”œâ”€ Query timeout settings<br/>   â””â”€ Index maintenance schedule"]
            
            hardware_recommendations["ğŸ–¥ï¸ Hardware Optimization<br/>System Configuration<br/>â”Œâ”€ CPU recommendations:<br/>â”‚  â”œâ”€ High core count (16+ cores)<br/>â”‚  â”œâ”€ Good single-thread performance<br/>â”‚  â”œâ”€ Large L3 cache (20MB+)<br/>â”‚  â””â”€ Modern instruction sets (AVX2+)<br/>â”œâ”€ Memory recommendations:<br/>â”‚  â”œâ”€ Large capacity (64GB+)<br/>â”‚  â”œâ”€ High bandwidth (DDR4-3200+)<br/>â”‚  â”œâ”€ Low latency modules<br/>â”‚  â””â”€ ECC for data integrity<br/>â”œâ”€ Storage recommendations:<br/>â”‚  â”œâ”€ NVMe SSD for database<br/>â”‚  â”œâ”€ High IOPS capability<br/>â”‚  â”œâ”€ Adequate capacity for growth<br/>â”‚  â””â”€ RAID for redundancy<br/>â””â”€ Network considerations:<br/>   â”œâ”€ High bandwidth (10GbE+)<br/>   â”œâ”€ Low latency connections<br/>   â”œâ”€ Dedicated data networks<br/>   â””â”€ Redundant connections"]
        end
    end
    
    %% Performance flow connections
    parse_benchmarks --> db_benchmarks
    parse_complexity --> db_scaling
    db_benchmarks --> worker_scaling
    db_scaling --> batch_optimization
    
    parsing_memory --> worker_memory
    worker_memory --> streaming_processing
    streaming_processing --> memory_pooling
    
    file_limits --> system_limits
    system_limits --> vertical_scaling
    vertical_scaling --> horizontal_scaling
    
    system_metrics --> application_metrics
    application_metrics --> config_tuning
    config_tuning --> hardware_recommendations
    
    classDef performanceMetric fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    classDef memoryAnalysis fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    classDef scalabilityLimit fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    classDef monitoring fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    
    class parse_benchmarks,parse_complexity,db_benchmarks,db_scaling,worker_scaling,batch_optimization performanceMetric
    class parsing_memory,worker_memory,streaming_processing,memory_pooling memoryAnalysis
    class file_limits,system_limits,vertical_scaling,horizontal_scaling scalabilityLimit
    class system_metrics,application_metrics,config_tuning,hardware_recommendations monitoring